{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41af22d",
   "metadata": {},
   "source": [
    "\n",
    "# 2. Method 1: Spectral Hashing\n",
    "## 2.1 The Problem: Open Modification Searching is Slow\n",
    "\n",
    "**Open Modification Searching (OMS)** is used to identify *post-translationally modified* peptides in mass spec data.\n",
    "\n",
    "* **Post Translational Modifications (PTMs):** Chemical \"add-ons\" to proteins after being synthesized. \n",
    "  * Eg. an oxygen atom \"sticking to\" a peptide is called oxidation, similarly for, say phosphorylation. This shifts the mass of the peptide by a certain m/z. So if a peak is at m/z = 230 with charge z, adding an oxygen atom (~16 Da) will shift it to approximately 230 + 16/z\n",
    "\n",
    "* Traditional proteomics search algorithms attempt to match fragmentation spectra by first identifying the mass of the intact peptide. Then, they only consider peptides from the database with a matching mass. This greatly reduces the search space from hundreds of thousands of peptides down to dozens.\n",
    "\n",
    "* In **OMS**, every peptide in the database is considered as a potential match to every MS2 fragmentation spectrum. When a peptide-spectrum match is found, you can look for *mass shifts* to identify PTMs. \"All possible modifications are implicitly considered.\"\n",
    "\n",
    "* **The catch:** OMS is computationally expensive because we compare every spectrum against *every peptide in the database*.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 The Approach: Clustering\n",
    "\n",
    "Instead of comparing every spectrum to every peptide, we can use **clustering** to group similar spectra together. If we know the identity of some spectra ahead of time (e.g., those identified using a traditional search), then we have a good idea of the identity of every spectrum in that cluster.\n",
    "\n",
    "This approach was used by [ANN-SoLo](https://pubs.acs.org/doi/full/10.1021/acs.jproteome.9b00291), which we'll follow throughout this notebook:\n",
    "\n",
    "<center><img src=\"ANN-SoLo-Graphical-Abstract.jpeg\" width=\"685\" height=\"400\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f9b216",
   "metadata": {},
   "source": [
    "## 2.3 The Lego Analogy\n",
    "\n",
    "To understand clustering, imagine you're building a large Lego set with ~2,000 pieces.\n",
    "\n",
    "**The naive approach:**\n",
    "* Dump all pieces out at once\n",
    "* For each instruction, search through the entire pile to find the piece you need\n",
    "\n",
    "**The clustering approach:**\n",
    "* Dump all pieces out at once\n",
    "* First, sort pieces into piles by shape (2x4 studs, 1x2 studs, etc.)\n",
    "* For each instruction, go directly to the relevant pile\n",
    "\n",
    "If you grab any piece from a pile, it's representative of all pieces in that pile. This lets you quickly skip irrelevant piles. Now imagine 2,000,000 pieces — the efficiency gain becomes enormous.\n",
    "\n",
    "> **Key insight:** There's a balance between \"too specific\" (too many small piles) and \"too generic\" (piles with mixed pieces). The same applies to clustering spectra.\n",
    "\n",
    "---\n",
    "\n",
    "For spectra, clustering works the same way:\n",
    "\n",
    "| Lego Approach | Spectra Approach |\n",
    "|--------------|------------------|\n",
    "| Group similar pieces into piles | Group similar spectra into clusters |\n",
    "| Identify one piece per pile | Identify one spectrum per cluster (using traditional search) |\n",
    "| All pieces in pile share that identity | All spectra in cluster share that peptide identity |\n",
    "\n",
    "This transforms millions of comparisons into just thousands!\n",
    "\n",
    "---\n",
    "\n",
    "#### How do we group spectra together?\n",
    "\n",
    "1. **Convert each spectrum into a vector** (a list of numbers capturing the spectrum's characteristics)\n",
    "2. **Measure distances between vectors** — similar spectra end up close together in multi-dimensional space\n",
    "3. **Group nearby vectors into clusters** — this is the actual \"clustering\"\n",
    "4. **Match by association** — unknown spectra inherit identities from known spectra in their cluster\n",
    "\n",
    "#### A visual example in 2D\n",
    "\n",
    "The graphics below walk through clustering spectra in 2 dimensions. In reality, we'll work with hundreds of dimensions, but the core idea is exactly the same.\n",
    "\n",
    "**Key insight: distance = similarity.** When two spectra map to nearby points, they're similar. When they're far apart, they're different.\n",
    "\n",
    "<br></br>\n",
    "<img src=\"Clustering-1.jpeg\" width=\"500\" height=\"675\">\n",
    "<img src=\"Clustering-2.jpeg\" width=\"500\" height=\"675\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af256778",
   "metadata": {},
   "source": [
    "## 2.4 From Peaks to Vectors: The Dimensionality Problem\n",
    "\n",
    "#### Understanding \"high-dimensional\" data\n",
    "\n",
    "When you look at a spectrum, you see 2 dimensions: m/z on the x-axis and intensity on the y-axis. But for clustering, we need to represent each spectrum as a single point in space.\n",
    "\n",
    "Imagine each possible m/z value as its own \"dimension.\" We create a vector mapping m/z bins to intensities:\n",
    "\n",
    "* Bin 1: m/z 100-101 (intensity = 0)\n",
    "* Bin 2: m/z 101-102 (intensity = 500)\n",
    "* Bin 3: m/z 102-103 (intensity = 0)\n",
    "* Bin 4: m/z 103-104 (intensity = 1200)\n",
    "* ... and so on\n",
    "\n",
    "This gives us a vector like `[0, 500, 0, 1200, ...]` where each position corresponds to one m/z bin. With 880 bins, that's an 880-dimensional vector!\n",
    "\n",
    "#### The challenge\n",
    "\n",
    "For fine precision (bins of 0.01 Da), we need 88,000 dimensions. That's computationally expensive for clustering algorithms.\n",
    "\n",
    "> **Lego analogy:** Imagine if instead of sorting by \"2x4 stud\" vs \"1x2 stud\", you sorted by exact color shade, manufacturing date, and serial number. You'd have thousands of tiny piles — too specific to be useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff31df7c",
   "metadata": {},
   "source": [
    "## 2.5 Spectral Embedding: The Two-Step Pipeline\n",
    "\n",
    "**Spectral embedding** compresses our high-dimensional representation (88,000 dimensions) down to a manageable size (800 dimensions) while preserving the important relationships between spectra.\n",
    "\n",
    "The ANN-SoLo paper breaks this into two steps:\n",
    "\n",
    "![fig-1.png](https://pubs.acs.org/cms/10.1021/acs.jproteome.9b00291/asset/images/medium/pr9b00291_0001.gif)\n",
    "\n",
    "| Step | What it does | Lego analogy |\n",
    "|------|-------------|--------------|\n",
    "| **Spectrum Binning** | Convert spectrum to sparse vector using fine m/z bins | Categorize pieces by precise measurements |\n",
    "| **Feature Hashing** | Compress sparse vector to fixed-size vector | Merge similar enough categories into manageable piles |\n",
    "\n",
    "We'll implement each step in detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed51ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @title Run this cell to import all necessary packages\n",
    "\n",
    "%pip install matplotlib\n",
    "\n",
    "import spectrum_utils.plot as sup\n",
    "import spectrum_utils.spectrum as sus\n",
    "import pyteomics\n",
    "from pyteomics import mzml, auxiliary\n",
    "import plotly.io as pio\n",
    "import plotly.tools as tls\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidhash import rapidhash\n",
    "from IPython.display import display, Latex\n",
    "from util import *\n",
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18037c73",
   "metadata": {},
   "source": [
    "Throughout our examples, we'll use one sample mzml file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fed875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run this to define our mzml paths\n",
    " \n",
    "full_calibrated_mzml_path = '04-17-23_CA_Tryp_HCD_10min_CLEAN-calib.mzML'\n",
    "\"\"\"\n",
    "Full, sample mzML file\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e869acf",
   "metadata": {},
   "source": [
    "The get_MS2_object function takes in a path and a scan number. This scan number tells it to retrieve the MS2 corresponding to the scan number from that mzML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329dce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2_spectrum_5672 = get_MS2_object(full_calibrated_mzml_path, 5672)\n",
    "plot_MS2(ms2_spectrum=ms2_spectrum_5672)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7dd78b",
   "metadata": {},
   "source": [
    "Grab the intensity and mz arrays from the object above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab mz values from that ms2 object as a list\n",
    "spectrum_mz = ms2_spectrum_5672.mz\n",
    "# grab intensity from that ms2 object as a list\n",
    "spectrum_int = ms2_spectrum_5672.intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cbb0d8",
   "metadata": {},
   "source": [
    "Here are the numerical values AKA how we represent our list of peaks:\n",
    "```python\n",
    "spectrum_mz =\n",
    "[129.10229301 147.11281745 185.16487986 186.16810345 213.15977385\n",
    " 229.11842622 260.19708681 298.14008063 300.15565245 328.18728919\n",
    " 347.22931143 348.23238243 462.25621643 463.25947053 484.20451703\n",
    " 575.34033321 646.37762047 647.38017268 743.39337543 761.40367098\n",
    " 762.4065894  763.40944677 874.48766569 875.49046204]\n",
    "\n",
    "\n",
    "spectrum_int =\n",
    "[2174.818  3145.84   9230.925  2883.7764 4380.564  2282.9873 3063.1228\n",
    " 2072.459  3142.8696 2672.6929 5380.33   2240.3975 6059.931  2831.662\n",
    " 2237.5989 3632.9626 4356.975  2494.9565 2366.8223 8133.1064 5098.785\n",
    " 2226.6924 4098.929  2766.6738]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01d93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intensity and mz values are parallel arrays, which you can either count the lengths of \n",
    "# or just assert and see it doesn't throw an error\n",
    "assert(len(spectrum_int) == len(spectrum_mz))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e897ae1",
   "metadata": {},
   "source": [
    "#### Choosing the right bin width\n",
    "\n",
    "Before we start binning, we need to choose our bin size. Using bins of 1 Da (rounding to nearest integer):\n",
    "\n",
    "* In the 129th idx: 2174.818\n",
    "* In the 147th idx: 3145.84\n",
    "* In the 185th idx: 9230.925\n",
    "* ... and so on for an array of length ~880\n",
    "\n",
    "---\n",
    "\n",
    "#### Why do we want at most 1 peak per bin?\n",
    "\n",
    "When each bin contains at most one peak, we preserve **maximum information**. If multiple peaks fall into the same bin, one intensity overwrites another — we lose data.\n",
    "\n",
    "> **Lego analogy:** If you dump all red 2x4s AND all blue 2x4s into the same pile, you can no longer distinguish them. For clustering spectra, we want to preserve as much detail as possible.\n",
    "\n",
    "If we had 200 unique m/z values ranging from 100–300 and rounded to the nearest integer, we'd quickly run into overlaps. Every value between 129.0 ≤ m/z < 130.0 would collapse into index 129.\n",
    "\n",
    "Finer-grained buckets reduce collisions:\n",
    "\n",
    "| Precision | Array Length (max m/z = 880) |\n",
    "|-----------|------------------------------|\n",
    "| 1 Da | 880 buckets |\n",
    "| 0.1 Da | 8,800 buckets |\n",
    "| 0.01 Da | 88,000 buckets |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bad0fb2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "#### Accurate vs. Naive approach\n",
    "\n",
    "Here's the Naive approach with making such a vector. Here, we round down each mz to the nearest integer.\n",
    "$$\n",
    "\\text{Approach 1: Rounding to nearest integer (1 Da bins)} \\\\[0.5em]\n",
    "\\begin{align}\n",
    "\\text{Here's a list with 880 zeroes filled in: } &\\quad [\\underset{0}{0}, \\underset{1}{0}, \\underset{2}{0}, \\ldots, \\underset{879}{0}, \\underset{880}{0}] \\\\[0.5em]\n",
    "\\text{Now, let's add a sample of such values at each index:} & \\quad [\\underset{0}{0}, \\ldots, \\underset{129}{2174.818}, \\ldots, \\underset{147}{3145.84}, \\ldots, \\underset{880}{0}] \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Like we mentioned though, this takes a lot of accuracy away, and results in quite a few collisions. The approach using finer (to the nearest 0.01 mz) buckets:\n",
    "\n",
    "$$\n",
    "\\text{Approach 2: Rounding to nearest 0.01 Da (higher precision)} \\\\[0.5em]\n",
    "\\begin{align}\n",
    "\n",
    "\\text{Here's a list with 88,000 zeroes filled in: } &\\quad [\\underset{0}{0}, \\underset{1}{0}, \\underset{2}{0}, \\ldots, \\underset{87999}{0}, \\underset{88000}{0}] \\\\[0.5em]\n",
    "\\text{Now, let's add a sample of such values at each index:} & \\quad [\\underset{0}{0}, \\ldots, \\underset{12910}{2174.818}, \\ldots, \\underset{14711}{3145.84}, \\ldots, \\underset{88000}{0}] \n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cd1362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run this to see the difference in collisions between widths\n",
    "plot_and_show_statistics_for_collisions(full_calibrated_mzml_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba81e87",
   "metadata": {},
   "source": [
    "This clearly demonstrates why we need a smaller bin size. However, we can't just make bins arbitrarily small, we must choose a size that is both fine enough to preserve information and realistic for mass spectrometer accuracy.\n",
    "\n",
    "The key consideration is that mass spectrometers have physical precision limitations. While a spectrometer might output a value like $ m/z =  10.023130 $, it cannot actually distinguish measurements to that level of precision. In practice, mass spectrometers are reliably accurate to approximately two decimal places (0.01 Da)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cecc209",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH_OF_BIN = 0.01\n",
    "LENGTH = int(max(spectrum_mz) // WIDTH_OF_BIN +1) # integer rounding up one.\n",
    "print(f\"We have to fit our m/zs into bins by rounding them to the nearest {WIDTH_OF_BIN}\")\n",
    "print(f\"The length of our (simulated) array will be {LENGTH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06df9a5a",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Step 1: Spectrum Binning\n",
    "\n",
    "Now we implement the first step of the pipeline:\n",
    "\n",
    "**Goal:** Convert the spectrum to a sparse vector using small mass bins (0.01 Da) to tightly capture fragment masses.\n",
    "\n",
    "> **Lego analogy:** This is like measuring each Lego piece precisely — recording exact dimensions rather than just \"small\" or \"large.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0413f0c6",
   "metadata": {},
   "source": [
    "We've already chosen our bin width (0.01 Da). Now we'll define a function to convert m/z values to their binned index.\n",
    "\n",
    "For example: 129.103 m/z → index 12910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a20fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Conversion to sparse vector\n",
    "\n",
    "def to_idx(mz):\n",
    "    \"\"\"\n",
    "    Convert m/z value to a sparse vector index.\n",
    "    \"\"\"\n",
    "    # concretely: 129.103 // 0.01 == 12910\n",
    "    return int(mz // WIDTH_OF_BIN) # rounds down to nearest 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62767c",
   "metadata": {},
   "source": [
    "#### Sparse vectors: An optimization\n",
    "\n",
    "With 88,000 possible bins but only ~24 peaks per spectrum, most bins are empty. Storing 88,000 zeros is wasteful.\n",
    "\n",
    "A **dictionary** stores only the non-zero entries:\n",
    "\n",
    "Instead of:\n",
    "```\n",
    "[0, 0, 0, ..., 2174.818, 0, 0, ..., 3145.84, 0, 0, ..., 0]  # 88,000 elements!\n",
    "```\n",
    "\n",
    "We store:\n",
    "```\n",
    "{12910: 2174.818, 14711: 3145.84, ...}  # Only 24 entries\n",
    "```\n",
    "\n",
    "> **Lego analogy:** Instead of labeling 88,000 empty bins, we just keep a list of which bins actually have pieces in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88256182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Create the sparse representation: map from m/z indices to intensities\n",
    "\n",
    "mz_intensity_map = {}\n",
    "# Populate the sparse vector with our spectrum data\n",
    "for i, mz in enumerate(spectrum_mz):\n",
    "    # Convert each m/z to its corresponding index\n",
    "    mz_index = to_idx(mz)\n",
    "    # Store the intensity\n",
    "    mz_intensity_map[mz_index] = spectrum_int[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fedc08",
   "metadata": {},
   "source": [
    "What does this look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794c7d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run to visualize the dictionary \n",
    "print(\"The map dictionary looks like:\\n\")\n",
    "print(f\"{'m/z bin':<12} {'Intensity':<12} {'Original m/z'}\")\n",
    "print(\"-\" * 40)\n",
    "for i, (idx, intensity) in enumerate(sorted(mz_intensity_map.items())):\n",
    "    print(f\"{idx:<12} {intensity:<12.3f} ({spectrum_mz[i]:.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40)\n",
    "print(f\"Total entries: {len(mz_intensity_map)} (instead of ~88,000 zeros!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64562161",
   "metadata": {},
   "source": [
    "**Step 1 complete!** We have a sparse representation of our spectrum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4bb67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 2: Feature Hashing\n",
    "\n",
    "Now for the second step of the pipeline:\n",
    "\n",
    "**Goal:** Compress the sparse vector (with indices up to 88,000) into a fixed-size vector of 800 dimensions.\n",
    "\n",
    "#### Why do we need this?\n",
    "\n",
    "Our sparse dictionary is memory-efficient, but we still have problems:\n",
    "- **Clustering algorithms need fixed-size vectors.** You can't easily compute distances between dictionaries with different keys.\n",
    "- **The potential dimensionality is still huge.** Even with only 24 entries, those indices span 0–88,000.\n",
    "\n",
    "#### What's a hash function?\n",
    "\n",
    "A **hash function** converts input data of any size into a fixed-size output:\n",
    "\n",
    "1. **Deterministic**: Same input → same output every time\n",
    "2. **Fixed output size**: Always the same length, regardless of input\n",
    "3. **Fast**: Efficiently computable\n",
    "\n",
    "> **Lego analogy:** This is like consolidating your 88,000 ultra-precise categories back into 800 practical piles. Pieces that were in nearby categories get merged together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a64d04b",
   "metadata": {},
   "source": [
    "#### How hashing works for our spectra\n",
    "\n",
    "A hash function maps any sparse index to a fixed range of buckets:\n",
    "\n",
    "$$\\text{hash}(12910) \\rightarrow 347 \\quad \\text{(bucket between 0 and 799)}$$\n",
    "\n",
    "$$\\text{hash}(14711) \\rightarrow 102 \\quad \\text{(another bucket)}$$\n",
    "\n",
    "**Key insight:** Similar spectra will have similar hash vectors because they share many of the same m/z bins, which hash to the same buckets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88ea800",
   "metadata": {},
   "source": [
    "#### Why 800 buckets?\n",
    "\n",
    "We balance two concerns:\n",
    "- **Large enough** to minimize collisions (different peaks hashing to the same bucket)\n",
    "- **Small enough** to be computationally efficient for clustering\n",
    "\n",
    "800 is a good middle ground for typical MS2 spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d153e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "HASH_BUCKETS = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039366f",
   "metadata": {},
   "source": [
    "#### The hash function\n",
    "\n",
    "We'll use `rapidhash`, a fast hash function, combined with the modulo operator to map any sparse index to a bucket in the range `[0, 799]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bd993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasher(num: int) -> int:\n",
    "    \"\"\"\n",
    "    Hash function that maps sparse indices to a fixed number of buckets.\n",
    "    \n",
    "    Input: Large sparse index (e.g., 12910)\n",
    "    Output: Small bucket index (0 to 799)\n",
    "    \"\"\"\n",
    "    # Convert integer to bytes for hashing (rapidhash expects byte input)\n",
    "    byte_representation = int(num).to_bytes(8, 'little')\n",
    "    \n",
    "    # Hash and mod to get bucket index in range [0, hash_buckets-1]\n",
    "    return rapidhash(byte_representation) % HASH_BUCKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b986abec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Title Example: see how large indices get mapped to small buckets\n",
    "print(f\"Sparse index 12910 → bucket {hasher(12910)}\")\n",
    "print(f\"Sparse index 14711 → bucket {hasher(14711)}\")\n",
    "print(f\"Sparse index 87550 → bucket {hasher(87550)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7faed7",
   "metadata": {},
   "source": [
    "#### Handling collisions\n",
    "\n",
    "What happens when two different m/z bins hash to the same bucket? This is called a **collision**. \n",
    "\n",
    "We handle collisions by **adding the intensities together**. As we will see in a minute, this is acceptable because it, on average, happens rarely enough that it \"preserves similarity\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e4f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our final hash vector with all zeros\n",
    "hash_vector = [0] * HASH_BUCKETS \n",
    "\n",
    "# Populate the hash buckets with intensities from our sparse map\n",
    "for sparse_idx, intensity in mz_intensity_map.items():\n",
    "    # Map the sparse index to a bucket\n",
    "    bucket_idx = hasher(sparse_idx)\n",
    "    \n",
    "    # Add intensity to that bucket (handles collisions by summation)\n",
    "    hash_vector[bucket_idx] += intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acc0382",
   "metadata": {},
   "source": [
    "#### The final hash vector\n",
    "\n",
    "Notice how the sparse map lets us iterate over only the non-zero entries — we never touch the ~88,000 zeros!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the hash vector\n",
    "non_zero_buckets = [(i, val) for i, val in enumerate(hash_vector) if val > 0]\n",
    "\n",
    "print(f\"Hash vector has {len(non_zero_buckets)} non-zero buckets out of {HASH_BUCKETS} total\\n\")\n",
    "\n",
    "nonzero_hash_df = pd.DataFrame(non_zero_buckets, columns=['Bucket', 'Intensity'])\n",
    "pd.set_option('display.float_format', lambda x: f'{x:.2f}')\n",
    "display(nonzero_hash_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a3b0a",
   "metadata": {},
   "source": [
    "**Step 2 complete!** We now have a fixed-size hash vector.\n",
    "\n",
    "---\n",
    "\n",
    "## 2.6 Summary: The Complete Pipeline\n",
    "\n",
    "We've completed the full spectral hashing pipeline:\n",
    "\n",
    "| Step | Representation | Size | Lego Analogy |\n",
    "|------|----------------|------|--------------|\n",
    "| **Original** | (m/z, intensity) pairs | 24 peaks | Raw pieces dumped out |\n",
    "| **Step 1: Binning** | Sparse dictionary | 24 entries (of 88,000 possible) | Precise measurements recorded |\n",
    "| **Step 2: Hashing** | Fixed-size vector | 800 dimensions | Consolidated into practical piles |\n",
    "\n",
    "---\n",
    "\n",
    "### Putting It All Together: The OMS Workflow\n",
    "\n",
    "Now we can see how spectral hashing enables efficient OMS. Define an embedding function:\n",
    "\n",
    "```python\n",
    "def embed_spectrum(mz_array, intensity_array) -> list[float]:\n",
    "    # Step 1: Bin → Step 2: Hash\n",
    "    return hash_vector  # length 800\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Phase 1: Build the Library (one-time preprocessing)**\n",
    "\n",
    "1. For all spectra with **known identity** (from a spectral library), imagine we have such a function:\n",
    "```python\n",
    "hash_vector_library = embed_spectrum(library_spectrum.mz: list[int], library_spectrum.intensity:list[int])\n",
    "```\n",
    "\n",
    "2. Cluster all library hash vectors using cosine similarity.\n",
    "\n",
    "> **Lego analogy:** Sort all your known Lego pieces into piles before you start building.\n",
    "\n",
    "---\n",
    "\n",
    "**Phase 2: Identify Unknown Spectra (query phase)**\n",
    "\n",
    "3. For each unknown **query spectrum**:\n",
    "```python\n",
    "hash_vector_query = embed_spectrum(query_spectrum.mz, query_spectrum.intensity)\n",
    "```\n",
    "\n",
    "4. Find the nearest cluster representative using cosine similarity.\n",
    "\n",
    "5. If similarity exceeds a threshold → assign the query the peptide identity of that cluster.\n",
    "\n",
    "> **Lego analogy:** When you need a piece, check which pile it belongs to. All pieces in that pile share ~ the same identity.\n",
    "\n",
    "---\n",
    "\n",
    "**Why does this work for modified peptides?**\n",
    "\n",
    "A modified peptide shares MOST of its fragment ions with the unmodified version. The modification only shifts a subset of peaks. Because of this shared structure, the hash vectors remain similar enough that modified and unmodified versions cluster together — enabling identification regardless of PTMs.\n",
    "\n",
    "> **Note:** We can only compare vectors of the same length. That's why Step 2 (hashing to a fixed 800 dimensions) is essential."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3e3c0",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 2.7 Similarity Preservation: Does Hashing Actually Work?\n",
    "\n",
    "We've claimed that hashing \"preserves similarity\" — that similar spectra remain similar after compression. Let's prove it.\n",
    "\n",
    "**What does \"preserve similarity\" mean?**\n",
    "\n",
    "If two spectra are similar in the original 88,000-dimensional space, they should also be similar in the compressed 800-dimensional space. The relative ordering of \"similar\" vs. \"dissimilar\" pairs should remain roughly the same.\n",
    "\n",
    "> **Lego analogy:** If two pieces were in the same ultra-precise category, they should end up in the same (or nearby) practical pile after consolidation.\n",
    "\n",
    "---\n",
    "\n",
    "#### Measuring similarity with cosine similarity\n",
    "\n",
    "We use the **dot product** to measure how similar two vectors are:\n",
    "\n",
    "$$\\vec{x} \\cdot \\vec{z} > \\vec{x} \\cdot \\vec{y} \\implies \\vec{x} \\text{ is more similar to } \\vec{z} \\text{ than to } \\vec{y}$$\n",
    "\n",
    "**Cosine similarity** is just a normalized dot product (scaled between -1 and 1, like...cosine!).\n",
    "\n",
    "**Example:**\n",
    "\n",
    "$\\vec{x} = [0, 500, 0, 1200] \\quad \\text{(Spectrum A)}$\n",
    "\n",
    "$\\vec{z} = [0, 480, 0, 1190] \\quad \\text{(Spectrum B — similar)}$\n",
    "\n",
    "$\\vec{y} = [100, 30, 2000, 0] \\quad \\text{(Spectrum C — different)}$\n",
    "\n",
    "**Dot products:**\n",
    "\n",
    "$\\vec{x} \\cdot \\vec{z} = (0)(0) + (500)(480) + (0)(0) + (1200)(1190) = 1,668,000$\n",
    "\n",
    "$\\vec{x} \\cdot \\vec{y} = (0)(100) + (500)(30) + (0)(2000) + (1200)(0) = 15,000$\n",
    "\n",
    "Since $1,668,000 \\gg 15,000$, spectra A and B would be **clustered together**.\n",
    "\n",
    "<details>\n",
    "<summary>Click to see the full cosine similarity formula</summary>\n",
    "\n",
    "$$\\cos(\\theta) = \\frac{\\vec{x} \\cdot \\vec{z}}{|\\vec{x}| |\\vec{z}|}$$\n",
    "\n",
    "where $\\theta$ is the angle between vectors. When $\\theta = 0°$ (identical direction), $\\cos(\\theta) = 1$. When $\\theta = 90°$ (perpendicular), $\\cos(\\theta) = 0$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68831ef",
   "metadata": {},
   "source": [
    "Click play to go through a visual example (no sound), starting from the top.\n",
    "\n",
    "<video controls>\n",
    "  <source src=\"SimilarityPreservationComplete.mp4\" type=\"video/mp4\">\n",
    "</video>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1490028e",
   "metadata": {},
   "source": [
    "> **Note:** Some similarity loss is expected due to hash collisions, but this loss is typically small and acceptable for clustering purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faa092",
   "metadata": {},
   "source": [
    "#### Empirical validation\n",
    "\n",
    "The code below compares pairwise similarities between spectra in both the original (sparse) and hashed representations. If hashing works, the correlation should be high.\n",
    "\n",
    "In simpler terms, did you notice that when we went from binned -> binned + hashed spectra, the peaks didn't keep their original spots? We'll show that a hash function actually does this so reliably, that we still KEEP the similarity or dissimilarity property of the original binned spectra. \n",
    "- Again, we are **not** comparing binned spectra to binned + hashed, we're following the video exactly, and ensuring that if 2 binned spectra are similar, then their respective hashed versions will also be similar.\n",
    "    - Like aforementioned, you also cannot actually compare two lists of 80,000 (binned) and 800 (binned + hashed) elements. This is another reason why we compare things in their respective \"spaces.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c38cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prove_similarity_preservation_plots_and_statistics(\"04-17-23_CA_Tryp_HCD_10min_CLEAN.mzML\") \n",
    "# This is a very computationally expensive task, we use a snippet of the original file for the sake of time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc7620c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Worked Example: Spectral Hashing End-to-End\n",
    "\n",
    "Now let's see the complete pipeline on real data. We'll work with the peptide **AVVQDPALKPLALVYGEATSR**.\n",
    "\n",
    "Below is its theoretical ion ladder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ion_ladder('AVVQDPALKPLALVYGEATSR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5943c132",
   "metadata": {},
   "source": [
    "Let's look at how this ion ladder can be plotted as a \"spectrum.\" The purpose of this is to visualize the spread of m/z values. The intensity values here are meaningless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_mz = [\n",
    "    72.044114, 171.112528, 270.180942, 398.239520, 513.266463,\n",
    "    610.319227, 681.356341, 794.440405, 922.535368, 1019.588132,\n",
    "    1132.672196, 1203.709310, 1316.793374, 1415.861788, 1578.925108,\n",
    "    1635.946572, 1764.989165, 1836.026279, 1937.073958, 2024.105986\n",
    "]\n",
    "\n",
    "y_mz = [\n",
    "    2127.179698, 2028.111284, 1929.042870, 1800.984292, 1685.957349,\n",
    "    1588.904585, 1517.867471, 1404.783407, 1276.688444, 1179.635680,\n",
    "    1066.551616, 995.514502, 882.430438, 783.362024, 620.298704,\n",
    "    563.277240, 434.234647, 363.197533, 262.149854, 175.117826\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4), dpi=100)\n",
    "\n",
    "# Equal heights (e.g., 1.0)\n",
    "height = 0.6\n",
    "ax.vlines(b_mz, 0, height, colors='#1976D2', linewidth=1.5, label='b-ions')\n",
    "ax.vlines(y_mz, 0, height, colors='#D32F2F',  linewidth=1.5, label='y-ions')\n",
    "\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_xlabel(\"m/z\")\n",
    "ax.set_ylabel(\"Intensity (arbitrary)\")\n",
    "ax.set_title(\"Theoretical ion ladder for AVVQDPALKPLALVYGEATSR\")\n",
    "ax.legend(frameon=False)\n",
    "ax.grid(True, axis='y', alpha=0.25)\n",
    "\n",
    "# b labels: b1, b3, b5, ...\n",
    "for i, x in enumerate(b_mz, start=1):\n",
    "    if i % 2 == 1:\n",
    "        ax.text(x, height*1.02, f\"b{i}\", rotation=90, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "# y_mz is descending (y20..y1). Convert to ion number j = y#\n",
    "n_y = len(y_mz)\n",
    "for i, x in enumerate(y_mz, start=1):\n",
    "    j = n_y - i + 1   # y ion number at this m/z\n",
    "    if j % 2 == 1:    # y1, y3, y5, ...\n",
    "        ax.text(x, height*1.02, f\"y{j}\", rotation=90, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335aa4ba",
   "metadata": {},
   "source": [
    "Now that we've visualized this theoretical ion ladder as a \"spectrum,\" let's plot a real spectrum and use the ion ladder to annotate it. The spectrum plotted below is the unmodified AVVQDPALKPLALVYGEATSR peptide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8610cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_MS2(get_MS2_object(full_calibrated_mzml_path, 9970, peptide = 'AVVQDPALKPLALVYGEATSR')) # Scan 9970 is the unmodified spectrum for sequence AVVQDPALKPLALVYGEATSR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1194b3",
   "metadata": {},
   "source": [
    "Although there is inevitable noise that deviates from the theoretical ion ladder, this spectrum overall aligns really well with the ladder. In other words, **a significant proportion of this spectrum's total intensity is accounted for by the theoretical ion ladder.** Let's now look at a modified version of AVVQDPALKPLALVYGEATSR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a4126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq = 'AVVQDPALKPLALVYGEATSR'\n",
    "\n",
    "spec_left  = get_MS2_object(full_calibrated_mzml_path, 9970, peptide=seq)\n",
    "spec_right = get_MS2_object(full_calibrated_mzml_path, 8090, peptide=seq)\n",
    "\n",
    "# Make two panels sharing axes so scales match\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=120, sharex=True, sharey=True)\n",
    "axes[0].set_xlabel(\"m/z\")\n",
    "axes[0].set_ylabel(\"Intensity\")\n",
    "\n",
    "# Left panel = unmodified = scan 9970\n",
    "sup.spectrum(spec_left, ax=axes[0], grid=True)\n",
    "axes[0].set_title(\"Unmodified (Scan 9970)\")\n",
    "\n",
    "# Right panel = modified = scan 8090\n",
    "sup.spectrum(spec_right, ax=axes[1], grid=True)\n",
    "axes[1].set_title(\"Modified (Scan 8090)\")\n",
    "\n",
    "fig.suptitle(\"AVVQDPALKPLALVYGEATSR — Unmodified vs. Modified\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])  # leave space at the top for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d2d7c",
   "metadata": {},
   "source": [
    "We can repeat that process using an unmodified and modified spectrum from each of the 2 other peptides in our mzml file: IITHPNFNGNTLDNDIMLIK and RMVNNGHSFNVEYDDSQDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892cb7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq = 'IITHPNFNGNTLDNDIMLIK'\n",
    "spec_left  = get_MS2_object(full_calibrated_mzml_path, 7567, peptide=seq)\n",
    "spec_right = get_MS2_object(full_calibrated_mzml_path, 8616, peptide=seq)\n",
    "\n",
    "# Make two panels sharing axes so scales match\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=120, sharex=True, sharey=True)\n",
    "axes[0].set_xlabel(\"m/z\")\n",
    "axes[0].set_ylabel(\"Intensity\")\n",
    "\n",
    "# Left panel = unmodified = scan 7567\n",
    "sup.spectrum(spec_left, ax=axes[0], grid=True)\n",
    "axes[0].set_title(\"Unmodified (Scan 7567)\")\n",
    "\n",
    "# Right panel = modified = scan 8616\n",
    "sup.spectrum(spec_right, ax=axes[1], grid=True)\n",
    "axes[1].set_title(\"Modified (Scan 8616)\")\n",
    "\n",
    "fig.suptitle(\"IITHPNFNGNTLDNDIMLIK — Unmodified vs. Modified\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])  # leave space at the top for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97665200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq = 'RMVNNGHSFNVEYDDSQDK'\n",
    "\n",
    "spec_left  = get_MS2_object(full_calibrated_mzml_path, 3864, peptide=seq)\n",
    "spec_right = get_MS2_object(full_calibrated_mzml_path, 4022, peptide=seq)\n",
    "\n",
    "# Make two panels sharing axes so scales match\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=120, sharex=True, sharey=True)\n",
    "axes[0].set_xlabel(\"m/z\")\n",
    "axes[0].set_ylabel(\"Intensity\")\n",
    "\n",
    "# Left panel = unmodified = scan 3864\n",
    "sup.spectrum(spec_left, ax=axes[0], grid=True)\n",
    "axes[0].set_title(\"Unmodified (Scan 3864)\")\n",
    "\n",
    "# Right panel = modified = scan 4022\n",
    "sup.spectrum(spec_right, ax=axes[1], grid=True)\n",
    "axes[1].set_title(\"Modified (Scan 4022)\")\n",
    "\n",
    "fig.suptitle(\"RMVNNGHSFNVEYDDSQDK — Unmodified vs. Modified\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])  # leave space at the top for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4b0f1",
   "metadata": {},
   "source": [
    "There are two \"trends\" you might be noticing by now: <br></br>\n",
    "1. Generally, when a spectrum (modified or unmodified) is annotated with the theoretical ion ladder for it's associated peptide, there is a significant proportion of that spectrum's intensity that is accounted for by the ion ladder.\n",
    "2. Unmodified spectra better \"match\" or are better \"accounted for\" by the peptide's theoretical ion ladder than modified spectra. But there is not a significant difference.\n",
    "<br></br>\n",
    "But what if we were to use the ion ladder of one peptide to annotate the spectrum of a different peptide? Let's try using the theoretical ion ladder of AVVQDPALKPLALVYGEATSR to annotate the spectrum of a modified RMVNNGHSFNVEYDDSQDK peptide. We'll plot that on the right panel. On the left, we'll plot the spectrum of a modified AVVQDPALKPLALVYGEATSR spectrum and annotate it with the AVVQDPALKPLALVYGEATSR ion ladder (just as we did above). In this case, we are plotting spectra from **2 different peptides** and annotating them with **1 ion ladder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd03401",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 'AVVQDPALKPLALVYGEATSR'\n",
    "\n",
    "spec_left  = get_MS2_object(full_calibrated_mzml_path, 8090, peptide=seq)\n",
    "spec_right = get_MS2_object(full_calibrated_mzml_path, 4022, peptide=seq)\n",
    "\n",
    "# Make two panels sharing axes so scales match\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=120, sharex=True, sharey=True)\n",
    "axes[0].set_xlabel(\"m/z\")\n",
    "axes[0].set_ylabel(\"Intensity\")\n",
    "\n",
    "# Left panel = modified AVVQDPALKPLALVYGEATSR = scan 8090\n",
    "sup.spectrum(spec_left, ax=axes[0], grid=True)\n",
    "axes[0].set_title(\"Modified AVVQDPALKPLALVYGEATSR (scan 8090)\")\n",
    "\n",
    "# Right panel = modified RMVNNGHSFNVEYDDSQDK = scan 4022\n",
    "sup.spectrum(spec_right, ax=axes[1], grid=True)\n",
    "axes[1].set_title(\"Modified RMVNNGHSFNVEYDDSQDK (Scan 4022)\")\n",
    "\n",
    "fig.suptitle(\"Annotation from AVVQDPALKPLALVYGEATSR Ion Ladder\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])  # leave space at the top for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5fddaf",
   "metadata": {},
   "source": [
    "Let's do that once more, but this time annotating the spectrum of the modified RMVNNGHSFNVEYDDSQDK peptide using the theoretical ion ladder of RMVNNGHSFNVEYDDSQDK (on the left) and AVVQDPALKPLALVYGEATSR (on the right). In this case, we are plotting **1 spectrum** and annotating it with **2 different ion ladders.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_1= 'RMVNNGHSFNVEYDDSQDK'\n",
    "seq_2 = 'AVVQDPALKPLALVYGEATSR'\n",
    "\n",
    "spec_left  = get_MS2_object(full_calibrated_mzml_path, 4022, peptide=seq_1)\n",
    "spec_right = get_MS2_object(full_calibrated_mzml_path, 4022, peptide=seq_2)\n",
    "\n",
    "# Make two panels sharing axes so scales match\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), dpi=120, sharex=True, sharey=True)\n",
    "axes[0].set_xlabel(\"m/z\")\n",
    "axes[0].set_ylabel(\"Intensity\")\n",
    "\n",
    "# Left panel = RMVNNGHSFNVEYDDSQDK Annotation, Scan 4022\n",
    "sup.spectrum(spec_left, ax=axes[0], grid=True)\n",
    "axes[0].set_title(\"RMVNNGHSFNVEYDDSQDK Annotation\")\n",
    "\n",
    "# Right panel = AVVQDPALKPLALVYGEATSR Annotation, scan 4022\n",
    "sup.spectrum(spec_right, ax=axes[1], grid=True)\n",
    "axes[1].set_title(\"AVVQDPALKPLALVYGEATSR Annotation\")\n",
    "\n",
    "fig.suptitle(\"Modified RMVNNGHSFNVEYDDSQDK Spectrum\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.94])  # leave space at the top for the suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d7978",
   "metadata": {},
   "source": [
    "Now, you're probably beginning to notice more meaningful trends. In the first example, where we annotated two different spectra (from different peptides) with the same ion ladder, a much greater proportion of the \"matching\" spectrum's intensity was accounted for by the ion ladder than of the other spectrum's intensity. In the second example, where we annotated the same spectrum using two different ion ladders (one belonging to the same peptide, and one not), a much greater proportion of the spectrum (annotated by it's associated peptide)'s intensity was accounted for by the ion ladder than of the spectrum (annoted by the other peptide)'s intensity. **Let's begin the binning process:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be17e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import SpectrumWithTransformations as swt_module\n",
    "import SpectrumWithTransformations\n",
    "from spectrum_utils.proforma import Modification\n",
    "\n",
    "importlib.reload(swt_module)\n",
    "\n",
    "# This function should read in an mzml file and return an object of type SpectrumWithTransformations\n",
    "# Based off of get_MS2_object from Sam Payne lesson 4\n",
    "def get_SWT_object(\n",
    "    mzml_path: str,\n",
    "    scan_number: int,\n",
    "    full_sequence = None,\n",
    ") -> \"SpectrumWithTransformations\":\n",
    "    \n",
    "    index = scan_number -1 #scan_number is 1-based, index is 0-based\n",
    "    with mzml.MzML(mzml_path, use_index=True) as reader: #use_index=True allows us to avoid reading through the entire mzml file\n",
    "        selected_spectrum = reader.get_by_index(index)\n",
    "    # Test to see if we accessed the correct scan: PASSED!\n",
    "    # precursor_mz = selected_spectrum['precursorList']['precursor'][0]['isolationWindow']['isolation window target m/z']\n",
    "    # print(precursor_mz)\n",
    "    \n",
    "\n",
    "    # This finds the cooresponding values in the .mzml file to create our MS2 for a given scan (see the params)\n",
    "    spectrum_id = selected_spectrum['id']\n",
    "    retention_time = selected_spectrum['scanList']['scan'][0]['scan start time']\n",
    "    precursor_mz = selected_spectrum['precursorList']['precursor'][0]['isolationWindow']['isolation window target m/z']\n",
    "    precursor_charge = int(selected_spectrum['precursorList']['precursor'][0]['selectedIonList']['selectedIon'][0]['charge state'])\n",
    "    mz_array = np.asarray(selected_spectrum['m/z array'])\n",
    "    intensity_array = np.asarray(selected_spectrum['intensity array'])\n",
    "    \n",
    "    swt_object = SpectrumWithTransformations.SpectrumWithTransformations(\n",
    "        identifier=spectrum_id,\n",
    "        scan_number=scan_number,\n",
    "        precursor_mz=precursor_mz,\n",
    "        precursor_charge=precursor_charge,\n",
    "        mz_array=mz_array,\n",
    "        intensity_array=intensity_array,\n",
    "        retention_time=retention_time,\n",
    "        annotation_dictionary=None,\n",
    "        binned_mz=None,\n",
    "        hashed_mz=None,\n",
    "    )\n",
    "\n",
    "    if full_sequence:\n",
    "        swt_object = swt_object.annotate_proforma(\n",
    "            proforma_str = full_sequence,\n",
    "            fragment_tol_mass = 0.01, # We consider two peaks (actual and theoretical) \"equivalent\" if they are within +/- 0.01 Da\n",
    "            fragment_tol_mode = 'Da',\n",
    "            ion_types = 'by',\n",
    "            max_ion_charge = max(1, precursor_charge - 1)\n",
    "        )\n",
    "    return swt_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eb884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spectrum_utils.proforma import Modification\n",
    "# Example with Scan 8090\n",
    "# mod_1 = Modification(  \n",
    "    # mass = 0.9848,\n",
    "    # position = 4,\n",
    "    # label = 'Deamidation'\n",
    "# )\n",
    "# modifications_list = [mod_1]\n",
    "\n",
    "scan_8090 = get_SWT_object(\n",
    "    mzml_path=full_calibrated_mzml_path,\n",
    "    scan_number = 8090,\n",
    "    full_sequence = 'AVVQ[Deamidated]DPALKPLALVYGEATSR',\n",
    ")\n",
    "\n",
    "plot_MS2(scan_8090, title='Scan 8090: Original Spectrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH_OF_BIN = 0.01\n",
    "def to_idx(num):\n",
    "    return int(num // WIDTH_OF_BIN)\n",
    "\n",
    "# Bin the mz\n",
    "scan_8090.binned_mz = np.empty_like(scan_8090.mz, dtype=int)\n",
    "for i in range(len(scan_8090.mz)):\n",
    "    scan_8090.binned_mz[i] = to_idx(scan_8090.mz[i])\n",
    "\n",
    "# Create a binned_spectrum SWT object for plotting purposes only\n",
    "binned_spectrum = get_SWT_object(\n",
    "    mzml_path=full_calibrated_mzml_path,\n",
    "    scan_number = 8090,\n",
    "    full_sequence = 'AVVQ[Deamidated]DPALKPLALVYGEATSR',\n",
    ")\n",
    "for i in range (len(binned_spectrum.mz)):\n",
    "    binned_spectrum.mz[i] = scan_8090.binned_mz[i] #Re-writing the mz_array with the binned mz values\n",
    "\n",
    "# Plot the binned spectrum\n",
    "plot_MS2(binned_spectrum, 'Scan 8090: Binned Spectrum')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78927ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HASH_BUCKETS = 800  # Target dimensionality\n",
    "\n",
    "def hasher(num: int) -> int:\n",
    "    \"\"\"\n",
    "    Hash function that maps sparse indices to a fixed number of buckets.\n",
    "\n",
    "    Input: Large sparse index (e.g., 12910)\n",
    "    Output: Small bucket index (0 to 399)\n",
    "    \"\"\"\n",
    "    # Convert integer to bytes for hashing (rapidhash expects byte input)\n",
    "    byte_representation = int(num).to_bytes(8, 'little')\n",
    "    # Hash and mod to get bucket index in range [0, hash_buckets-1]\n",
    "    return rapidhash(byte_representation) % HASH_BUCKETS\n",
    "\n",
    "# Set-up\n",
    "hashed_mz = []\n",
    "hashed_intensity = []\n",
    "hash_vector = [0] * HASH_BUCKETS\n",
    "mz_intensity_map = {}\n",
    "for i, mz in enumerate(scan_8090.mz):\n",
    "    mz_intensity_map[to_idx(mz)] = scan_8090.intensity[i]\n",
    "\n",
    "# Hash the mz and add the intensities as we go\n",
    "for sparse_idx, intensity in mz_intensity_map.items():\n",
    "    bucket_idx = hasher(sparse_idx)\n",
    "    hash_vector[bucket_idx] += intensity\n",
    "    hashed_mz.append(bucket_idx)\n",
    "    hashed_intensity.append(hash_vector[bucket_idx])\n",
    "\n",
    "# Update the hashed mz and intensities\n",
    "scan_8090.hashed_mz = hashed_mz\n",
    "scan_8090.hashed_intensity = hashed_intensity\n",
    "\n",
    "# Create a hashed_spectrum SWT object for plotting purposes only\n",
    "hashed_spectrum = get_SWT_object(\n",
    "    mzml_path=full_calibrated_mzml_path,\n",
    "    scan_number = 8090,\n",
    "    full_sequence = 'AVVQ[Deamidated]DPALKPLALVYGEATSR',\n",
    ")\n",
    "for i in range (len(hashed_spectrum.mz)):\n",
    "    hashed_spectrum.mz[i] = scan_8090.hashed_mz[i] #Re-writing the mz_array with the hashed mz values\n",
    "    hashed_spectrum.intensity[i] = scan_8090.hashed_intensity[i] #Re-writing the intensity_array with the summed intensity values\n",
    "\n",
    "# Plot the hashed spectrum\n",
    "plot_MS2(hashed_spectrum, 'Scan 8090: Hashed Spectrum')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bed987",
   "metadata": {},
   "source": [
    "### Side by side\n",
    "<img src=\"Scan8090_Original.png\" width=\"400\" height=\"300\">\n",
    "<img src=\"Scan8090_Binned.png\" width=\"400\" height=\"300\">\n",
    "<img src=\"Scan8090_Hashed.png\" width=\"400\" height=\"300\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
