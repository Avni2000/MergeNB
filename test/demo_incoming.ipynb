{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a889a7",
   "metadata": {},
   "source": [
    "## Tiny Feedforward Neural Net (No Frameworks)\n",
    "\n",
    "This notebook creates and trains a small feedforward neural network on a synthetic binary classification problem.\n",
    "\n",
    "We'll only use numpy and matplotlib to build, train, and visualize a tiny model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae803824",
   "metadata": {},
   "source": [
    "## Step 1: Gradient Descent\n",
    "\n",
    "We need a few things to get started. The first is some kind of optimization algorithm. A simple choice is gradient descent, which iteratively updates parameters in the direction of the negative gradient of the loss function. We'll also eventually need a loss function to optimize with gradient descent, but for now let's just focus on the optimization algorithm itself.\n",
    "\n",
    "\n",
    "Recall from calculus that $\\frac{d(x^2)}{dx} = 2x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdce054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_descent(iterations: int, learning_size: float, init: int) -> float:\n",
    "    \"\"\"This is a summary\n",
    "\n",
    "    Args:\n",
    "        iterations (int): _description_\n",
    "        learning_size (float): _description_\n",
    "        init (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        float: _description_\n",
    "    \"\"\"\n",
    "    minimizer = init\n",
    "    # Start from initial point and move towards minimum\n",
    "    for _ in range(iterations):\n",
    "        d = 2*minimizer\n",
    "        minimizer = minimizer - learning_size * d\n",
    "    return round(minimizer, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e9cae",
   "metadata": {},
   "source": [
    "Let's see what happens when we apply this algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1139fe17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# This should converge to 0.\n",
    "print(grad_descent(iterations=100, learning_rate=0.1, init=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30f3209",
   "metadata": {},
   "source": [
    "As we can see, the algorithm converges to the minimum of the function, which is at $x=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125f9f38",
   "metadata": {},
   "source": [
    "Let's apply this to our feed forward net!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
